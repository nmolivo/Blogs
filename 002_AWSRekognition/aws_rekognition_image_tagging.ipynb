{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook tasks:\n",
    "### - Save images to an AWS S3 bucket\n",
    "### - Use AWS Rekognition to reverse image search and return tags for each image\n",
    "### - Saves data in both long and wide data frames\n",
    "Brought to you by Natalie Olivo<br>\n",
    "<a href = https://www.linkedin.com/in/natalie-olivo-82548951/>LinkedIn</a><br>\n",
    "<a href = https://nmolivo.github.io/NMOstatic/>Website</a><br>\n",
    "<a href = https://medium.com/@NatalieOlivo>Blog</a><br>\n",
    "<a href = https://github.com/nmolivo>GitHub</a><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"newtweets_10percent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_list = df['link_thumbnail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#make sure it looks good!\n",
    "test_1 = image_list[3]\n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto\n",
    "import boto3\n",
    "conn = boto.connect_s3()\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uses the creds in ~/.aws/credentials\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name_to_upload_image_to = '#########' #insert the name of your bucket here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do this as a quick and easy check to make sure your S3 access is OK\n",
    "for bucket in s3.buckets.all():\n",
    "    if bucket.name == bucket_name_to_upload_image_to:\n",
    "        print('Good to go. Found the bucket to upload the image into.')\n",
    "        good_to_go = True\n",
    "\n",
    "if not good_to_go:\n",
    "    print('Not seeing your s3 bucket, might want to double check permissions in IAM')\n",
    "# I learned this trick from the answers to this Stack Overflow question:\n",
    "# https://stackoverflow.com/questions/14346065/upload-image-available-at-public-url-to-s3-using-boto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### We received all our images in the form of links. \n",
    "### We need our images saved to an S3 bucket, preferably without saving them to our hard drive.\n",
    "\n",
    "### Don't have a bucket? What is a bucket? http://docs.aws.amazon.com/AmazonS3/latest/user-guide/create-bucket.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping_dict ={}\n",
    "for i, img_url in enumerate(image_list[0:10000]):\n",
    "    img_name = \"img_%05d\" % (i,)\n",
    "    mapping_dict[img_name] = img_url\n",
    "    \n",
    "    if (img_url == np.nan) | (str(img_url) == \"nan\"):\n",
    "        continue\n",
    "    else:\n",
    "        # Uses the creds in ~/.aws/credentials\n",
    "        s3_image_filename = img_name\n",
    "        internet_image_url = img_url\n",
    "\n",
    "        # Given an Internet-accessible URL, download the image and upload it to S3,\n",
    "        # without needing to persist the image to disk locally\n",
    "        req_for_image = requests.get(internet_image_url, stream=True)\n",
    "        file_object_from_req = req_for_image.raw\n",
    "        req_data = file_object_from_req.read()\n",
    "\n",
    "        # Do the actual upload to s3\n",
    "        s3.Bucket(bucket_name_to_upload_image_to).put_object(Key=s3_image_filename, Body=req_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save down your mapping dict so that you can eventually re-map your image tags to your full dataframe.\n",
    "mapping_dict = pd.DataFrame(mapping_dict, index = range(0,len(mapping_dict)))\n",
    "mapping_dict = pd.DataFrame(md_01.T[0])\n",
    "mapping_dict.to_csv('mappingdict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developer notes: Below is code for component parts of a big for-loop that creates both wide and long dataframes with image information gathered from AWS Rekognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So first off you probably want to look at the output of each tool in rekognition.  (It's different for each one!)\n",
    "#I'm going to focus on:\n",
    "#DetectObjects\n",
    "#RecognizeCelebrities\n",
    "#TextDetection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://docs.aws.amazon.com/rekognition/latest/dg/get-started-exercise.html\n",
    "fileName= 'img_######'\n",
    "bucket='##########'\n",
    "client=boto3.client('rekognition')\n",
    "## ^^ we only need to do this code once for the following examples. but I include it \n",
    "##    re-instated in case you want to check out different pics.\n",
    "\n",
    "response = client.detect_labels(Image={'S3Object':{'Bucket':bucket,'Name':fileName}},MinConfidence=75)\n",
    "# Notes on detecting people\n",
    "# min confidence 75 return labels = [\"person\", \"people\", \"human\"]\n",
    "# min confidence ~50 returns labels = [\"blonde\", \"woman\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take a look at the output\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detect_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName= 'img_######'\n",
    "bucket='##########'\n",
    "\n",
    "text_in_image = client.detect_text(Image={'S3Object':{'Bucket':bucket,'Name':fileName}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_in_image.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_in_image[\"TextDetections\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recognize_celebrities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileName= 'img_######'\n",
    "bucket='##########'\n",
    "\n",
    "celeb_detect = client.recognize_celebrities(Image={'S3Object':{'Bucket':bucket,'Name':fileName}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "celeb_detect.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "celeb_detect['CelebrityFaces'][0]['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big for-loop that creates both wide and long df's with our image tags from Rekognition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12/1 Notes: Sometimes due to network conditions, it will throw an error on a specific record. When ran again, that same record will not throw an error.\n",
    "12/1 Notes: This takes a long time to run. May want to only test on ~20 images at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bucket_name = '##########'\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "images = [img.key for img in bucket.objects.all()]\n",
    "client = boto3.client('rekognition')\n",
    "\n",
    "results_wide = []\n",
    "results_long = []\n",
    "\n",
    "for img in images:\n",
    "    img_dict_wide = {'img': img}\n",
    "    #print(img)\n",
    "    try:\n",
    "        labels = client.detect_labels(Image={'S3Object':{'Bucket':bucket_name,'Name':img}},MinConfidence=75)\n",
    "        if 'Labels' in labels:\n",
    "            for l, label in enumerate(labels['Labels']):\n",
    "                results_long.append({'img': img, 'type': 'Label', 'label': label['Name'], \n",
    "                                     'confidence': label['Confidence']})\n",
    "                col = 'label_' + str(l)\n",
    "                img_dict_wide[col] = label['Name']\n",
    "                img_dict_wide[col + '_confidence'] = label['Confidence'] \n",
    "    except:\n",
    "        continue\n",
    "    try:        \n",
    "        celebrities = client.recognize_celebrities(Image={'S3Object':{'Bucket':bucket_name,'Name':img}})\n",
    "        if 'CelebrityFaces' in celebrities:\n",
    "            for f, face in enumerate(celebrities['CelebrityFaces']):\n",
    "                results_long.append({'img': img, 'type': 'Celebrity', 'label': face['Name'], \n",
    "                                     'confidence': face['Face']['Confidence']})\n",
    "                col = 'celeb_' + str(f)\n",
    "                img_dict_wide[col] = face['Name']\n",
    "                img_dict_wide[col + '_confidence'] = face['Face']['Confidence']\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        text_in_image = client.detect_text(Image={'S3Object':{'Bucket':bucket_name,'Name':img}})\n",
    "        if \"TextDetections\" in text_in_image:\n",
    "            for w, word in enumerate(text_in_image[\"TextDetections\"]):\n",
    "                results_long.append({'img': img, 'type': \"Text\", 'label': word[\"DetectedText\"],\n",
    "                                    'confidence': word[\"Confidence\"]})\n",
    "                col = 'word_' + str(w)\n",
    "                img_dict_wide[col] = word[\"DetectedText\"]\n",
    "                img_dict_wide[col+ '_confidence'] = word[\"Confidence\"]\n",
    "    except:\n",
    "        continue\n",
    "            \n",
    "    if 'Labels' not in labels and 'CelebrityFaces' not in celebrities and \"TextDetections\" not in text_in_image:\n",
    "        results_long.append({'img': img, 'type': None, 'label': None, 'confidence': None})\n",
    "        \n",
    "    results_wide.append(img_dict_wide)\n",
    "####\n",
    "####\n",
    "img_df_long = pd.DataFrame(results_long, columns=['img', 'type', 'label', 'confidence'])\n",
    "img_df_wide = pd.DataFrame(results_wide)\n",
    "cols = sorted(img_df_wide.columns)\n",
    "cols.remove('img')\n",
    "img_df_wide = img_df_wide[['img'] + cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save down your dfs.\n",
    "\n",
    "#For our topic modelers only focused on images data!\n",
    "img_df_long.to_csv(\"twitter_img_text_long.csv\")\n",
    "\n",
    "#For mapping to the dataframe provided to us by TM\n",
    "img_df_wide.to_csv(\"twitter_img_text_wide.csv\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
